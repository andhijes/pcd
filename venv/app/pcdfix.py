# -*- coding: utf-8 -*-
"""pcd

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_KhTicGqVeNO7e8CCZ80MroTsTnn4Uzu
"""



import pandas as pd
mangga = pd.read_csv('mangga.csv', delimiter=';')

"""# Classification

## **Exploration Data**
"""

#print(mangga.head())

#print(mangga.describe().transpose())

#print(mangga.shape)

"""## Train Test Split"""

Xclass = mangga.drop('Kematangan',axis=1)
Xclass = Xclass.drop('luas',axis=1)
Xclass = Xclass.drop('Berat',axis=1)
yclass = mangga['Kematangan']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(Xclass, yclass)
print()

"""## Preprocessing"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)
StandardScaler(copy=True, with_mean=True, with_std=True)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

"""## Training Model"""

from sklearn.neural_network import MLPClassifier
mlp = MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500)
mlp.fit(X_train,y_train)


"""## Prediction"""

predictions = mlp.predict(X_test)
from sklearn.metrics import classification_report,confusion_matrix
#print(confusion_matrix(y_test,predictions))
#print(classification_report(y_test,predictions))


"""## Buat ngetest klasifikasi"""
#misal barisnya
testbaris = [[45.42237509758,46.6865241998439,13.7977100274688,0.966212919594067,0.0337870804059329]]
#di praproses
testbaris = scaler.transform(testbaris)
#diprediksi
predictions = mlp.predict(testbaris)
print("Buat ngetest \n")
#hasil prediksi
print(predictions)


"""## Buat ngetest regresi"""
#misal input
luas = 0.1
#model
berat = -54.6064 + 3184.4924*luas
#hasil berat
print("hasil berat \n")
print(berat)

#yang dibawah ini g penting

"""## Draw Neural Network"""

import matplotlib.pyplot as plt
import numpy as np

def draw_neural_net(ax, left, right, bottom, top, layer_sizes, coefs_, intercepts_, n_iter_, loss_):
    '''
    Draw a neural network cartoon using matplotilb.
    
    :usage:
        >>> fig = plt.figure(figsize=(12, 12))
        >>> draw_neural_net(fig.gca(), .1, .9, .1, .9, [4, 7, 2])
    
    :parameters:
        - ax : matplotlib.axes.AxesSubplot
            The axes on which to plot the cartoon (get e.g. by plt.gca())
        - left : float
            The center of the leftmost node(s) will be placed here
        - right : float
            The center of the rightmost node(s) will be placed here
        - bottom : float
            The center of the bottommost node(s) will be placed here
        - top : float
            The center of the topmost node(s) will be placed here
        - layer_sizes : list of int
            List of layer sizes, including input and output dimensionality
    '''
    n_layers = len(layer_sizes)
    v_spacing = (top - bottom)/float(max(layer_sizes))
    h_spacing = (right - left)/float(len(layer_sizes) - 1)
    
    # Input-Arrows
    layer_top_0 = v_spacing*(layer_sizes[0] - 1)/2. + (top + bottom)/2.
    for m in xrange(layer_sizes[0]):
        plt.arrow(left-0.18, layer_top_0 - m*v_spacing, 0.12, 0,  lw =1, head_width=0.01, head_length=0.02)
    
    # Nodes
    for n, layer_size in enumerate(layer_sizes):
        layer_top = v_spacing*(layer_size - 1)/2. + (top + bottom)/2.
        for m in xrange(layer_size):
            circle = plt.Circle((n*h_spacing + left, layer_top - m*v_spacing), v_spacing/8.,
                                color='w', ec='k', zorder=4)
            if n == 0:
                plt.text(left-0.125, layer_top - m*v_spacing, r'$X_{'+str(m+1)+'}$', fontsize=15)
            elif (n_layers == 3) & (n == 1):
                plt.text(n*h_spacing + left+0.00, layer_top - m*v_spacing+ (v_spacing/8.+0.01*v_spacing), r'$H_{'+str(m+1)+'}$', fontsize=15)
            elif n == n_layers -1:
                plt.text(n*h_spacing + left+0.10, layer_top - m*v_spacing, r'$y_{'+str(m+1)+'}$', fontsize=15)
            ax.add_artist(circle)
    # Bias-Nodes
    for n, layer_size in enumerate(layer_sizes):
        if n < n_layers -1:
            x_bias = (n+0.5)*h_spacing + left
            y_bias = top + 0.005
            circle = plt.Circle((x_bias, y_bias), v_spacing/8., color='w', ec='k', zorder=4)
            plt.text(x_bias-(v_spacing/8.+0.10*v_spacing+0.01), y_bias, r'$1$', fontsize=15)
            ax.add_artist(circle)   
    # Edges
    # Edges between nodes
    for n, (layer_size_a, layer_size_b) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):
        layer_top_a = v_spacing*(layer_size_a - 1)/2. + (top + bottom)/2.
        layer_top_b = v_spacing*(layer_size_b - 1)/2. + (top + bottom)/2.
        for m in xrange(layer_size_a):
            for o in xrange(layer_size_b):
                line = plt.Line2D([n*h_spacing + left, (n + 1)*h_spacing + left],
                                  [layer_top_a - m*v_spacing, layer_top_b - o*v_spacing], c='k')
                ax.add_artist(line)
                xm = (n*h_spacing + left)
                xo = ((n + 1)*h_spacing + left)
                ym = (layer_top_a - m*v_spacing)
                yo = (layer_top_b - o*v_spacing)
                rot_mo_rad = np.arctan((yo-ym)/(xo-xm))
                rot_mo_deg = rot_mo_rad*180./np.pi
                xm1 = xm + (v_spacing/8.+0.05)*np.cos(rot_mo_rad)
                if n == 0:
                    if yo > ym:
                        ym1 = ym + (v_spacing/8.+0.12)*np.sin(rot_mo_rad)
                    else:
                        ym1 = ym + (v_spacing/8.+0.05)*np.sin(rot_mo_rad)
                else:
                    if yo > ym:
                        ym1 = ym + (v_spacing/8.+0.12)*np.sin(rot_mo_rad)
                    else:
                        ym1 = ym + (v_spacing/8.+0.04)*np.sin(rot_mo_rad)
                plt.text( xm1, ym1,\
                         str(round(coefs_[n][m, o],4)),\
                         rotation = rot_mo_deg, \
                         fontsize = 10)
    # Edges between bias and nodes
    for n, (layer_size_a, layer_size_b) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):
        if n < n_layers-1:
            layer_top_a = v_spacing*(layer_size_a - 1)/2. + (top + bottom)/2.
            layer_top_b = v_spacing*(layer_size_b - 1)/2. + (top + bottom)/2.
        x_bias = (n+0.5)*h_spacing + left
        y_bias = top + 0.005 
        for o in xrange(layer_size_b):
            line = plt.Line2D([x_bias, (n + 1)*h_spacing + left],
                          [y_bias, layer_top_b - o*v_spacing], c='k')
            ax.add_artist(line)
            xo = ((n + 1)*h_spacing + left)
            yo = (layer_top_b - o*v_spacing)
            rot_bo_rad = np.arctan((yo-y_bias)/(xo-x_bias))
            rot_bo_deg = rot_bo_rad*180./np.pi
            xo2 = xo - (v_spacing/8.+0.01)*np.cos(rot_bo_rad)
            yo2 = yo - (v_spacing/8.+0.01)*np.sin(rot_bo_rad)
            xo1 = xo2 -0.05 *np.cos(rot_bo_rad)
            yo1 = yo2 -0.05 *np.sin(rot_bo_rad)
            plt.text( xo1, yo1,\
                 str(round(intercepts_[n][o],4)),\
                 rotation = rot_bo_deg, \
                 fontsize = 10)    
                
    # Output-Arrows
    layer_top_0 = v_spacing*(layer_sizes[-1] - 1)/2. + (top + bottom)/2.
    for m in xrange(layer_sizes[-1]):
        plt.arrow(right+0.015, layer_top_0 - m*v_spacing, 0.16*h_spacing, 0,  lw =1, head_width=0.01, head_length=0.02)
    
    # Record the n_iter_ and loss
    plt.text(left + (right-left)/3., bottom - 0.005*v_spacing, \
             'Steps:'+str(n_iter_)+'    Loss: ' + str(round(loss_, 6)), fontsize = 15)
    
fig = plt.figure(figsize=(12, 12))
ax = fig.gca()
ax.axis('off')

my_hidden_layer_sizes= (13,13,13)
layer_sizes = [5] + list(my_hidden_layer_sizes) + [1]
draw_neural_net(ax, .1, .9, .1, .9, layer_sizes, mlp.coefs_, mlp.intercepts_, mlp.n_iter_, mlp.loss_)
fig.savefig('nn_digaram.png')

"""## Tuning"""

from sklearn.model_selection import GridSearchCV
# define the grid search parameters
param_grid = {'hidden_layer_sizes': [(5,), (5,5,), (5,5,5,), (13,), (13,13,), (13, 13, 13,), (20,), (20,20,), (20,20,20,)]}
grid = GridSearchCV(estimator=mlp, param_grid=param_grid, n_jobs=-1)
grid_result = grid.fit(Xclass, yclass)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

"""## New Model"""

mlpnew = MLPClassifier(hidden_layer_sizes=(20,),max_iter=500)
mlpnew.fit(X_train,y_train)

predictions = mlpnew.predict(X_test)
print(confusion_matrix(y_test,predictions))
print(classification_report(y_test,predictions))

"""## Draw new neural network"""


my_hidden_layer_sizes= (20,)
layer_sizes = [5] + list(my_hidden_layer_sizes) + [1]
draw_neural_net(ax, .1, .9, .1, .9, layer_sizes, mlpnew.coefs_, mlpnew.intercepts_, mlpnew.n_iter_, mlpnew.loss_)
fig.savefig('nn_digaram.png')

"""# Regression

## Set x and y
"""

Xreg = mangga['luas']
yreg = mangga['Berat']

"""## Modeling without constant"""

import statsmodels.api as sm


# Note the difference in argument order
model = sm.OLS(yreg, Xreg).fit()

predictions = model.predict(Xreg) # make the predictions by the model

# Print out the statistics
model.summary()

"""## Add constant"""

Xreg = sm.add_constant(Xreg)

"""##Modeling with constant"""

model = sm.OLS(yreg, Xreg).fit()

predictions = model.predict(Xreg) # make the predictions by the model

# Print out the statistics
model.summary()

"""##Plot"""

import seaborn as sns

sns.regplot(x='luas', y='Berat', data=mangga)

"""## Outlier"""

test = model.outlier_test()
outliers = ((Xreg[i],yreg[i]) for i,t in enumerate(test) if t[2] < 0.5)
print 'Outliers: ', list(outliers)